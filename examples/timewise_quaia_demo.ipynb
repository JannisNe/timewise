{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "![](https://raw.githubusercontent.com/JannisNe/timewise/refs/heads/main/timewise.png)\n",
    "# Infrared light curves from WISE data\n",
    "\n",
    "This package downloads WISE data for positions on the sky and stacks single-exposure photometry per visit. It is designed to do so for efficiently for large samples of millions of objects. For more info see the repo [here](https://github.com/JannisNe/timewise).\n",
    "\n",
    "## Prerequisites\n",
    "Python version 3.11, 3.12 or 3.13.\n",
    "\n",
    "If you want to not only download individual exposure photometry but also stack detections per visit (see below),\n",
    "you must have access to a running [MongoDB](https://www.mongodb.com/)* **. If you are running this notebook online you can make a free MongoDB Atlas account [here](https://www.mongodb.com/products/platform). Also make sure to allow access from your current IP address in the \"Network Access\" section of your MongoDB Atlas dashboard (or `0.0.0.0/0` to allow access from anywhere).\n",
    "\n",
    "<sub>* On MacOS have alook at the custom `brew` tap\n",
    "[here](https://github.com/mongodb/homebrew-brew)\n",
    "to get the MongoDB community edition. </sub>\n",
    "\n",
    "<sub>** On some systems this is not straight forward to set up. `timewise` requires it nevertheless as an integral part of the AMPEL system which is used to efficiently schedule and store the stacking of lightcurves. If you do not foresee a big overhead in calculating lightcurves for a sample of O(1000) objects, a more lightweight package might be more applicable. </sub>\n"
   ],
   "metadata": {
    "id": "mcSw7t5jLtZ8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Installation\n",
    "\n",
    "### If you use timewise only for downloading\n",
    "The package can be installed via `pip` (but make sure to install the v1 pre-release):\n",
    "```bash\n",
    "pip install --pre timewise==1.0.0a10\n",
    "```\n",
    "### If you use timewise also for stacking individual exposures\n",
    "You must install with the `ampel` extra:\n",
    "```bash\n",
    "pip install --pre 'timewise[ampel]==1.0.0a10'\n",
    "```\n",
    "To tell AMPEL which modules, aka units, to use, build the corresponding configuration file:\n",
    "```bash\n",
    "ampel config build -distributions ampel timewise -stop-on-errors 0 -out <path-to-ampel-config-file>\n",
    "```\n",
    "\n",
    "We will install with the `ampel` dependency:"
   ],
   "metadata": {
    "id": "eF0oWI0FMYKI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install timewise[ampel]==1.0.0a10"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Fka4FEDIJSD",
    "outputId": "2b18c06d-407f-4db6-f29e-5f63e3c6533f"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Command line interface"
   ],
   "metadata": {
    "id": "LhshtT8sMfxN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!timewise --help"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nxVLblwjIK9S",
    "outputId": "0fe72206-4489-4d75-fdce-e542526413e8"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The input is a CSV file with at least three columns:  \n",
    "- `orig_id`: an original identifier that **must** be an integer (for now)\n",
    "- `ra`, `dec`: Right Ascension and Declination\n",
    "\n",
    "As an example, let's use the first ten quasars from the Quaia catalog [(Kate Storey-Fisher et al 2024 ApJ 964 69)](https://iopscience.iop.org/article/10.3847/1538-4357/ad1328):"
   ],
   "metadata": {
    "id": "0lRCXehpMjyr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install wget"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8otoFVRhRjYy",
    "outputId": "520ed36f-b979-4823-c693-4763f4915e26"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import wget\n",
    "from astropy.table import Table\n",
    "\n",
    "# download the quaia catalog from zenodo\n",
    "working_directory = Path(\"./\").resolve()\n",
    "download_file = working_directory / \"quaia_G20.0.fits\"\n",
    "quaia_url = \"https://zenodo.org/records/10403370/files/quaia_G20.0.fits?download=1\"\n",
    "wget.download(quaia_url, str(download_file))\n",
    "\n",
    "# open the catalog and save the first ten object to a CSV file\n",
    "csv_file = download_file.with_suffix(\".csv\")\n",
    "t = Table.read(download_file).to_pandas().iloc[:10]\n",
    "t[\"orig_id\"] = t[\"source_id\"]\n",
    "t.to_csv(csv_file, index=False)\n",
    "download_file.unlink()\n",
    "\n",
    "# let's display the content\n",
    "pd.read_csv(csv_file)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "YVf93g7-Mkb1",
    "outputId": "e2331b8a-ffac-44f3-d6f9-c58c927c4003"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "`timewise` is configured with a YAML file. Below is a sensible default* which will use all single exposure photometry from AllWISE and NEOWISE in a 6 arcsecond radius around each source:\n",
    "\n",
    "<sub>\n",
    "* The MongoDB URI will depend on your specific set-up. If you installed a local instance with e.g. `brew` you do not have to specify this field to use the default mongodb://localhost:27017\n",
    "</sub>"
   ],
   "metadata": {
    "id": "4y8YRJydQKGW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "yaml_string = \"\"\"\n",
    "download:\n",
    "  input_csv: {path_to_input}\n",
    "  n_per_chunk: 100000\n",
    "\n",
    "  backend:\n",
    "    type: filesystem\n",
    "    base_path: {path_to_working_directory}\n",
    "\n",
    "  queries:\n",
    "    - type: positional\n",
    "      radius_arcsec: 6\n",
    "      table:\n",
    "        name: allwise_p3as_mep\n",
    "      columns:\n",
    "        - ra\n",
    "        - dec\n",
    "        - mjd\n",
    "        - cntr_mf\n",
    "        - w1mpro_ep\n",
    "        - w1sigmpro_ep\n",
    "        - w2mpro_ep\n",
    "        - w2sigmpro_ep\n",
    "        - w1flux_ep\n",
    "        - w1sigflux_ep\n",
    "        - w2flux_ep\n",
    "        - w2sigflux_ep\n",
    "\n",
    "    - type: positional\n",
    "      radius_arcsec: 6\n",
    "      table:\n",
    "        name: neowiser_p1bs_psd\n",
    "      columns:\n",
    "        - ra\n",
    "        - dec\n",
    "        - mjd\n",
    "        - allwise_cntr\n",
    "        - w1mpro\n",
    "        - w1sigmpro\n",
    "        - w2mpro\n",
    "        - w2sigmpro\n",
    "        - w1flux\n",
    "        - w1sigflux\n",
    "        - w2flux\n",
    "        - w2sigflux\n",
    "\n",
    "ampel:\n",
    "  mongo_db_name: {mongodb_name}\n",
    "  uri: {uri}\n",
    "\"\"\""
   ],
   "metadata": {
    "id": "6ly5t6ukUaRL"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Let's fill the variables in the yaml configuration and save it to a file. The `mongo_uri` will depend on your set-up. If you have a local MongoDB instance, it is likely running at `mongodb://localhost:27017`. If you are using MongoDB Atlas, you can find the connection string in the \"Connect\" section of your cluster dashboard.",
   "metadata": {
    "id": "s1A2B3WsUxzW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "mongo_uri = ...\n",
    "formatted_yaml_string = yaml_string.format(\n",
    "    path_to_input=str(csv_file),\n",
    "    path_to_working_directory=str(working_directory / \"timewise_data\"),\n",
    "    uri=mongo_uri,\n",
    "    mongodb_name=\"quaia_timewise_demo\",\n",
    "    )\n",
    "\n",
    "timewise_config_file = working_directory / \"quaia_timewise.yml\"\n",
    "with timewise_config_file.open(\"w\") as f:\n",
    "  f.write(formatted_yaml_string)"
   ],
   "metadata": {
    "id": "HnzguP9xUpdM"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This configuration file will be the input to all subcommands. Downloading and stacking can be run together or separate.\n"
   ],
   "metadata": {
    "id": "7_HldVlPWAaU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Query and download the data:\n"
   ],
   "metadata": {
    "id": "0Po1z2caWFYB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!timewise download --help"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3pdbH9lMWHH8",
    "outputId": "f495e43b-5342-4868-81e1-4fbfab91e4da"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "!timewise download quaia_timewise.yml"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yfw_hWBgWIeU",
    "outputId": "d66ef748-9cf3-4274-b7ad-7febe05d6b25"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can find the query results in the configure directory. The FITS files contain the raw photometry:"
   ],
   "metadata": {
    "id": "1U_5fcgWWr9M"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!ls timewise_data/"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Hdn8kuAfWZWf",
    "outputId": "46ae09fc-23e2-4d09-d333-73c0766080d5"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "Table.read(\"./timewise_data/download_chunk0000_positional_neowiser_p1bs_psd_db292e4d5b65426a060a4ec349984298948e16e89f998b6bb4e965fd20a299a6.fits\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506
    },
    "id": "tpI3aiatXDuu",
    "outputId": "df58b327-5f7e-4a5d-d6f4-2e101068a58a"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stack individual exposure by visits\n",
    "\n",
    "As mentioned above, `timewise` is designed to compute lightcurves for many objects. It used the AMPEL system to do that. To tell AMPEL which modules (\"units\" in AMPEL terms) to use, build the corresponding configuration file:"
   ],
   "metadata": {
    "id": "P7wkw4bEXqmw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!ampel config build -distributions ampel timewise -stop-on-errors 0 -out ampel_config.yml"
   ],
   "metadata": {
    "collapsed": true,
    "id": "C71S-r3yXUL4"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The ampel config is built assuming a local MongoDB instance at `mongodb://localhost:27017`. Let's use a remote MongoDB instead."
   ],
   "metadata": {
    "id": "0ElhVMfZcMk3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "with open(\"ampel_config.yml\", \"r\") as f:\n",
    "  config_string = f.read()\n",
    "\n",
    "config_string_remote_db = config_string.replace(\"mongodb://localhost:27017\", mongo_uri)\n",
    "\n",
    "with open(\"ampel_config.yml\", \"w\") as f:\n",
    "  f.write(config_string_remote_db)"
   ],
   "metadata": {
    "id": "mD8cQEk1e3rU"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you are using MongoDB Atlas: you have to delete the `storageEngine` specification in the config file!"
   ],
   "metadata": {
    "id": "_PxiQIaPHbII"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some `timewise` utility to help you set up your AMPEL job file:"
   ],
   "metadata": {
    "id": "Xx_xOz9cffrd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!timewise prepare-ampel quaia_timewise.yml"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oiWKAmP8fAk1",
    "outputId": "c2c4247a-98a8-45e4-f7f0-2ad74c3bd1c1"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This imports the input into the MongoDB as well as create a standard AMPEL job file:"
   ],
   "metadata": {
    "id": "gnvLUpP9gf1y"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!cat quaia_timewise_ampel_job.yml"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cq3ElmDafmPS",
    "outputId": "d9753a64-bf32-41a3-905c-35fc215ff101"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This might be confuding at first! Here is an attempt of an explanation. AMPEL runs so-called units (`unit` keyword in the job file). Each unit can be configured individually (`config` keyword in the configuration file).\n",
    "\n",
    "The workflow above defines two tasks:\n",
    "\n",
    "#### 1. `t0`\n",
    "This loads the downloaded data from the configured timewise data directory (`TimewiseFileLoader`) and supplies the data per object in the format demanded by AMPEL (`TimewiseAlertSupplier`). Each individual datapoint will be ingested into the database, making sure no duplicate data is present (`TiMongoMuxer`). This is especially helpful for duplicate entris in the AllWISE MEP database (see [this](https://irsa.ipac.caltech.edu/data/WISE/docs/release/AllWISE/expsup/sec1_3.html) for more info). The data per object will be selected as the closest cluster at the position of the parent sample object as explained in [Necker at al. (2024)](https://www.aanda.org/articles/aa/abs/2025/03/aa51340-24/aa51340-24.html) (`T1HDBSCAN`). For each comiled set of datapoints, The calculation of the stacked lightcurve is scheduled (`T2StackVisits`).\n",
    "\n",
    "\n",
    "#### 2. `t2`\n",
    "All scheduled calculations of tier 2 (T2) units is executed.\n",
    "\n",
    "`T1HDBSCAN` uses the position of the parent sample objects stored in the database. We have to tell the config again which MongoDB we are using:"
   ],
   "metadata": {
    "id": "qS1JOYDRguxu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"quaia_timewise_ampel_job.yml\", \"r\") as f:\n",
    "  ampel_job = yaml.safe_load(f)\n",
    "\n",
    "ampel_job[\"task\"][0][\"config\"][\"directives\"][0][\"ingest\"][\"mux\"][\"combine\"][0][\"config\"][\"mongo\"] = mongo_uri\n",
    "ampel_job[\"task\"][0][\"config\"][\"directives\"][0][\"ingest\"][\"mux\"][\"combine\"][0][\"config\"][\"plot\"] = False\n",
    "\n",
    "with open(\"quaia_timewise_ampel_job.yml\", \"w\") as f:\n",
    "  yaml.safe_dump(ampel_job, f)"
   ],
   "metadata": {
    "id": "xmW6kORoJQkV"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now run the AMPEL job:"
   ],
   "metadata": {
    "id": "TPrcGZa1CDRw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!ampel job -schema quaia_timewise_ampel_job.yml -config ampel_config.yml -task 2"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTF6dp3dg_fu",
    "outputId": "31889713-73dc-455d-d363-b3d5488c346a"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some diagnostic plots:"
   ],
   "metadata": {
    "id": "o631Rk3xCKK5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!mkdir ./timewise_plots\n",
    "!timewise plot quaia_timewise.yml 10892037246720 54838142692736 ./timewise_plots"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vfNjqMMR70cu",
    "outputId": "589f76b7-8de4-4575-d97d-518c02c0d5c7"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Further process stacked lightcurves\n",
    "\n",
    "#### Option 1: Export\n",
    "If you want to extract the stacked lightcurves to further process them with your own framework, do this:"
   ],
   "metadata": {
    "id": "XTxOuVPOC4A-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!timewise export quaia_timewise.yml ./timewise_export\n",
    "!ls ./timewise_export"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iwUy-2Rl_zMg",
    "outputId": "8f168562-00c4-4f9b-feff-2450cd841cf5"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Option 2: Leverage AMPEL power\n",
    "\n",
    "Due to AMPEL's inherent modularity, you can add your own AMPEL units to process the lightcurves, extract features, aggregate results, etc. Below is an example job file from ongoing work in [this repo](https://github.com/JannisNe/airgn):\n",
    "\n",
    "```yaml\n",
    "channel:\n",
    "- access:\n",
    "  - ZTF_PUB\n",
    "  name: wise\n",
    "  policy: []\n",
    "  version: 0\n",
    "mongo:\n",
    "  prefix: desi_agn_test_var_metrics\n",
    "  reset: false\n",
    "name: timewise\n",
    "task:\n",
    "- config:\n",
    "    compiler_opts: TiCompilerOptions\n",
    "    directives:\n",
    "    - channel: wise\n",
    "      ingest:\n",
    "        mux:\n",
    "          combine:\n",
    "          - state_t2:\n",
    "            - unit: T2StackVisits\n",
    "            - unit: T2CalculateVarMetrics\n",
    "              config:\n",
    "                t2_dependency:\n",
    "                  - unit: T2StackVisits\n",
    "            unit: T1SimpleCombiner\n",
    "          unit: TiMongoMuxer\n",
    "    iter_max: 1000000\n",
    "    shaper: TiDataPointShaper\n",
    "    supplier:\n",
    "      config:\n",
    "        dpid: hash\n",
    "        loader:\n",
    "          config:\n",
    "            timewise_config_file: $AIRGNSOURCE/airgn/desi/desi_agn_value_added_catalog.yml\n",
    "            stock_id_column_name: orig_id\n",
    "          unit: TimewiseFileLoader\n",
    "      unit: TimewiseAlertSupplier\n",
    "  multiplier: 1\n",
    "  title: t0\n",
    "  template:\n",
    "    live:\n",
    "      - resolve_run_time_aliases\n",
    "      - hash_t2_config\n",
    "  unit: AlertConsumer\n",
    "\n",
    "- config:\n",
    "    log_profile: default\n",
    "  multiplier: 1\n",
    "  title: t2\n",
    "  unit: T2Worker\n",
    "\n",
    "- title: PlotChi2\n",
    "  unit: T3Processor\n",
    "  config:\n",
    "    raise_exc: true\n",
    "    supply:\n",
    "      unit: T3DefaultBufferSupplier\n",
    "      config:\n",
    "        select:\n",
    "          unit: T3StockSelector\n",
    "          config:\n",
    "            channel: \"wise\"\n",
    "        load:\n",
    "          unit: T3SimpleDataLoader\n",
    "          config:\n",
    "            directives:\n",
    "              - T2DOC\n",
    "              - STOCK\n",
    "            channel: \"wise\"\n",
    "        chunk_size: 10000\n",
    "    stage:\n",
    "      unit: T3SimpleStager\n",
    "      config:\n",
    "        execute:\n",
    "          - unit: VarMetricsVsAGN\n",
    "            config:\n",
    "              path: $AIRGNDATA/desi_value_added_catalog/plots/test_var_vs_agn\n",
    "              input_mongo_db_name: desi_agn_vac\n",
    "              file_format: \"pdf\"\n",
    "              n_points_bins: [25, 30]\n",
    "              metric_names:\n",
    "                - pearsons_r\n",
    "                - red_chi2\n",
    "                - normalized_excess_variance\n",
    "                - inverse_von_neumann_ratio\n",
    "```\n",
    "\n"
   ],
   "metadata": {
    "id": "qpy83G95DY8s"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "s5jzdeQLDWb9"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
